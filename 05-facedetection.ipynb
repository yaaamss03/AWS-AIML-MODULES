{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Face Detection Lab - Student Notebook\n",
    "\n",
    "In this lab, you will use Amazon Rekognition to perform a facial detection of a known face.\n",
    "\n",
    "The high-level steps you will perform in this lab are:\n",
    "\n",
    "1. Create a collection.\n",
    "\n",
    "2. Upload an image of a face that you want to detect to the Amazon SageMaker notebook.\n",
    "\n",
    "3. Add the image to the collection.\n",
    "\n",
    "4. View the bounding box that was created for the image.\n",
    "\n",
    "5. List the faces in the collection.\n",
    "\n",
    "6. Use the collection to find a face.\n",
    "\n",
    "7. View the bounding box of the face that was found.\n",
    "\n",
    "8. Delete the collection.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Python packages\n",
    "\n",
    "Start by importing the Python packages that you need.\n",
    "\n",
    "In the following code:\n",
    "\n",
    "- *matplotlib* provides plotting functions\n",
    "- *skimage* represents scikit-image, which provides several useful image manipulation tools\n",
    "- *boto3* represents the AWS SDK for Python (Boto3), which is the Python library for AWS\n",
    "- *numpy* represents NumPy, which is a library for manipulating data\n",
    "- *PIL* represents the Python Imaging Library, which contains a set of tools for drawing images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from skimage.transform import rescale\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import boto3\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageColor, ImageOps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Creating a collection\n",
    "\n",
    "In this task, you create a collection in Amazon Rekognition.\n",
    "\n",
    "You only need to run this step once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('rekognition')\n",
    "collection_id = 'Collection'\n",
    "response = client.create_collection(CollectionId=collection_id)\n",
    "print('Collection ARN: ' + response['CollectionArn'])\n",
    "print('Status Code:' + str(response['StatusCode']))\n",
    "print('Done...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Uploading an image to search\n",
    "\n",
    "Use the provided sample image, which is named *mum.jpg*, and upload it to this notebook.\n",
    "\n",
    "Then, look at the image by running the cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"mum.jpg\"\n",
    "\n",
    "faceimage = io.imread(filename)\n",
    "\n",
    "plt.imshow(faceimage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Make sure that the image size is less than 4096 x 4096 pixels. If the image is larger than this size, then you must resize it by using the following code:\n",
    "\n",
    "`faceimage = rescale(faceimage, 0.50, mode='constant')`\n",
    "\n",
    "**Note:** The numeric value represents the factor to scale by. A value of *0.5* will scale the image to 50 percent of the original.\n",
    "\n",
    "When the image is resized, save the file.\n",
    "\n",
    "`io.imsave(filename, faceimage)`\n",
    "\n",
    "**Tip:** You must copy the code into a code cell and run it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Adding the image to the collection\n",
    "\n",
    "Add the image to the collection that you created earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "externalimageid = filename\n",
    "\n",
    "with open(filename, 'rb') as fimage:\n",
    "    response = client.index_faces(CollectionId = collection_id,\n",
    "                             Image={'Bytes': fimage.read()},\n",
    "                             ExternalImageId=externalimageid,\n",
    "                             MaxFaces=1,\n",
    "                             QualityFilter=\"AUTO\",\n",
    "                             DetectionAttributes=['ALL'])\n",
    "\n",
    "print('Results for ' + filename)\n",
    "print('Faces indexed:')\n",
    "for faceRecord in response['FaceRecords']:\n",
    "     print('  Face ID: ' + faceRecord['Face']['FaceId'])\n",
    "     print('  Location: {}'.format(faceRecord['Face']['BoundingBox']))\n",
    "\n",
    "print('Faces not indexed:')\n",
    "for unindexedFace in response['UnindexedFaces']:\n",
    "    print(' Location: {}'.format(unindexedFace['FaceDetail']['BoundingBox']))\n",
    "    print(' Reasons:')\n",
    "    for reason in unindexedFace['Reasons']:\n",
    "        print('   ' + reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Viewing the bounding box for the detected face\n",
    "\n",
    "If a face was found, the results should include the location of the face that was detected. Examine the bounding box on the image.\n",
    "\n",
    "To do this, use the PIL library, which you imported earlier in this lab. By extracting the BoundingBox, you can draw a set of lines around the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = Image.open(filename)\n",
    "imgWidth, imgHeight = img.size\n",
    "\n",
    "draw = ImageDraw.Draw(img)\n",
    "for faceRecord in response['FaceRecords']:\n",
    "    box = faceRecord['Face']['BoundingBox']\n",
    "    left = imgWidth * box['Left']\n",
    "    top = imgHeight * box['Top']\n",
    "    width = imgWidth * box['Width']\n",
    "    height = imgHeight * box['Height']\n",
    "\n",
    "    points = ((left,top),(left+width,top),(left+width,top+height),(left,top+height),(left,top))\n",
    "\n",
    "    draw.line(points,fill='#00d400', width=15)\n",
    "    \n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Listing faces in the collection\n",
    "\n",
    "Examine the image that you have in the collection. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxResults=2\n",
    "faces_count=0\n",
    "tokens=True\n",
    "\n",
    "response=client.list_faces(CollectionId=collection_id,\n",
    "                           MaxResults=maxResults)\n",
    "\n",
    "print('Faces in collection ' + collection_id)\n",
    "\n",
    "while tokens:\n",
    "\n",
    "    faces=response['Faces']\n",
    "\n",
    "    for face in faces:\n",
    "        print (face)\n",
    "        faces_count+=1\n",
    "    if 'NextToken' in response:\n",
    "        nextToken=response['NextToken']\n",
    "        response=client.list_faces(CollectionId=collection_id,\n",
    "                                   NextToken=nextToken,MaxResults=maxResults)\n",
    "    else:\n",
    "        tokens=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Finding a face by using the collection\n",
    "\n",
    "In this step, you will use the collection to detect a face in an image.\n",
    "\n",
    "Use the provided sample image that's named *target.jpg* and upload it to this notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetfilename = \"target.jpg\"\n",
    "\n",
    "targetimage = Image.open(targetfilename)\n",
    "plt.imshow(targetimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, call the `search_faces_by_image` operation and see if you get a match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 70\n",
    "maxFaces=2\n",
    "\n",
    "with open(targetfilename, 'rb') as timage:        \n",
    "    response2=client.search_faces_by_image(CollectionId=collection_id,\n",
    "                            Image={'Bytes': timage.read()},\n",
    "                            FaceMatchThreshold=threshold,\n",
    "                            MaxFaces=maxFaces)\n",
    "\n",
    "faceMatches=response2['FaceMatches']\n",
    "print ('Matching faces')\n",
    "for match in faceMatches:\n",
    "        print ('FaceId:' + match['Face']['FaceId'])\n",
    "        print ('Similarity: ' + \"{:.2f}\".format(match['Similarity']) + \"%\")\n",
    "        print ('ExternalImageId: ' + match['Face']['ExternalImageId'])\n",
    "        print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Drawing a bounding box around the discovered face\n",
    "\n",
    "Draw a bounding box around the discovered face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgWidth, imgHeight = targetimage.size\n",
    "\n",
    "draw = ImageDraw.Draw(targetimage)\n",
    "\n",
    "box = response2['SearchedFaceBoundingBox']\n",
    "left = imgWidth * box['Left']\n",
    "top = imgHeight * box['Top']\n",
    "width = imgWidth * box['Width']\n",
    "height = imgHeight * box['Height']\n",
    "\n",
    "points = ((left,top),(left+width,top),(left+width,top+height),(left,top+height),(left,top))\n",
    "draw.line(points,fill='#00d400', width=15)\n",
    "    \n",
    "plt.imshow(targetimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Deleting the collection\n",
    "\n",
    "When you are finished, delete the collection. To do this, run the following code. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Attempting to delete collection ' + collection_id)\n",
    "status_code=0\n",
    "try:\n",
    "    response=client.delete_collection(CollectionId=collection_id)\n",
    "    status_code=response['StatusCode']\n",
    "    print('All done!')\n",
    "    print(status_code)\n",
    "    \n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'ResourceNotFoundException':\n",
    "        print ('The collection ' + collection_id + ' was not found ')\n",
    "    else:\n",
    "        print ('Error other than Not Found occurred: ' + e.response['Error']['Message'])\n",
    "    status_code=e.response['ResponseMetadata']['HTTPStatusCode']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "You have completed this lab, and you can now end the lab by following the lab guide instructions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
